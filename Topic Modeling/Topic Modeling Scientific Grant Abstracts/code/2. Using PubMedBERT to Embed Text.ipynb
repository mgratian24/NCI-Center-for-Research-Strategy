{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25eb885e-9130-445c-92f7-cb9c12c848b2",
   "metadata": {},
   "source": [
    "# Topic Modeling Scientific Text\n",
    "\n",
    "*This template and workflow were developed by Margaret Gratian. This set of notebooks can be used to find topics in scientific text.*\n",
    "____________________________________\n",
    "## 2. Produce PubMedBERT Embeddings\n",
    "\n",
    "**Notebook Goals**\n",
    "- Demonstrate the process to embed abstracts from NIH grants using the PubMedBERT model so that they can be used for topic modeling.\n",
    "\n",
    "**Major Caveats**\n",
    "- When using Transformer-based models to embed text, preprocessing steps such as removing stop words are not necessary (and in fact, should not be done because Transformer models use context to produce embeddings). However, abstracts from NIH RePORTER often begin with phrases such as \"Project Summary\" or \"Abstract.\" You might optionally consider removing these with regular expressions, though it is not essential and is not done here.\n",
    "\n",
    "**Requirements**\n",
    "- This notebook requires the sentence-transformers library. Learn more about it here: https://sbert.net/.\n",
    "- Please see the README for instructions and recommendations on proper installation.\n",
    "\n",
    "**Embedding Details**\n",
    "- This notebook uses the PubMedBERT model to produce embeddings of size 768: https://huggingface.co/NeuML/pubmedbert-base-embeddings\n",
    "- This model is a PubMed-base model fine-tuned using Sentence Transformers. The base model was original built by Microsoft: https://huggingface.co/microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\n",
    "\n",
    "**References**\n",
    "\n",
    "We make use of work from the following papers:\n",
    "- Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint: [arXiv:1908.10084](https://arxiv.org/abs/1908.10084).\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "The following assumes you used the recommended path for saving your data in Notebook 1. If you modified it, be sure to modify the input path here.\n",
    "\n",
    "- Input Filepath 1: \"../data/reporter_results.csv\"\n",
    "    - Table of awards from a RePORTER request.\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "The following is a recommended path for saving your data. If you modify it, be sure to modify the inputs and outputs of subsequent notebooks.\n",
    "\n",
    "- Output Filepath 1: \"../data/pubmedbert_embeddings.csv\"\n",
    "     - Grant abstracts embedded with the PubMedBERT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865773d-e137-4afa-885e-29525d164b73",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9022bf5-bf2e-4522-9bd2-93e06a861040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de218580-1724-469b-a745-c421deb3a43a",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722ae27-3d43-48c5-8ff7-8690e3a02f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(text, model):\n",
    "    \"\"\"\n",
    "    Takes as input text and an embedding model and returns the embedding as a list. Note that models must already be loaded for this\n",
    "    to work.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text: string\n",
    "        A string of the text to embed\n",
    "    model: SentenceTransformer object \n",
    "        A pre-trained embedding model\n",
    "\n",
    "    Returns:\n",
    "    ---------\n",
    "    embedding: list of ints\n",
    "        List representing the vector embedding the text. \n",
    "    \"\"\"\n",
    "    \n",
    "    # First check that text is not empty\n",
    "    if pd.isna(text):\n",
    "        # Return None, not possible to emebd\n",
    "        return\n",
    "\n",
    "    # Get the embedding\n",
    "    embedding = model.encode([text])\n",
    "    \n",
    "    # Return the embedding\n",
    "    # Note embeddings are returned as a nested list \n",
    "    # Return the first element because we are embedding one sentence at a time\n",
    "    return embedding[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac165a1-f923-4191-a308-ddb11bfbb1d5",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba0d94f-c581-4cac-931d-4c822fc42004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the tabular PubMed data\n",
    "input_df = pd.read_csv(\"../data/reporter_results.csv\", index_col=0)\n",
    "print(input_df.shape)\n",
    "\n",
    "# Preview\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f5a5f-00b7-4949-8b20-3b86fdc5815f",
   "metadata": {},
   "source": [
    "## Load Pre-Trained Embedding Model\n",
    "\n",
    "https://huggingface.co/sentence-transformers/allenai-specter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472c75e1-e35b-429d-ba76-769d029c41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the allenai-specter model with SentenceTransformers\n",
    "model = SentenceTransformer(\"neuml/pubmedbert-base-embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558a612-5aff-45ba-9cbe-0156ed838fbd",
   "metadata": {},
   "source": [
    "## Dataset Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918c46d9-6e62-4624-8516-2360f79ad687",
   "metadata": {},
   "source": [
    "### Prep Data for Embedding\n",
    "\n",
    "- First make a copy of input_df\n",
    "- Drop rows with missing abstracts\n",
    "- Check that the data is unique for Appl Id (the NIH application ID that uniquely identifies awarded applications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d86b47-47d5-4d39-96e8-17524f89ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the input data \n",
    "embedded_df = input_df.copy()\n",
    "print(embedded_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf853fc-6c9a-4154-839f-fa58c19e6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm we don't have duplicates\n",
    "embedded_df = embedded_df.drop_duplicates()\n",
    "print(embedded_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efcb9f-923f-4d52-8cb6-93f1e0d47675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any with missing abstracts\n",
    "embedded_df = embedded_df.dropna(subset=[\"abstract_text\"])\n",
    "print(embedded_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64a9519-fc81-469e-a0fa-8bb62f6dfd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the data is unique for Appl Id, which uniquely identifies records\n",
    "embedded_df[[\"appl_id\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b180f7-afab-4b65-b11d-0db2e965337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "embedded_df[[\"abstract_text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c49e2-f7b9-4051-b4aa-94a3639a2de9",
   "metadata": {},
   "source": [
    "### Embed Titles and Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6cfe2-6945-44db-b484-0091cc1a05dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the embedding model to each title + abstract and save as a new column\n",
    "embedded_df[\"abstract_text_embedding\"] = embedded_df[\"abstract_text\"].apply(embed, args=(model,))\n",
    "\n",
    "# See column info\n",
    "embedded_df[\"abstract_text_embedding\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bad73-0cb8-4482-9d1e-cce1da5e8913",
   "metadata": {},
   "source": [
    "### Preview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b717e63-44a7-42cd-aaf9-186b8ba4e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90232cf8-fbde-4e71-ba40-4bc03098a2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we have no missing embedded abstracts\n",
    "embedded_df[[\"abstract_text\", \"abstract_text_embedding\"]].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae123c4d-aea8-4a7f-89e9-0a9539768fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at an example - we have vectors of size 768\n",
    "print(len(embedded_df.at[0,\"abstract_text_embedding\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69968e89-c027-4d01-b6ad-ade025620df6",
   "metadata": {},
   "source": [
    "## Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148f0fc-f92c-419e-933a-d971d309729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dfs with embeddings\n",
    "embedded_df.to_csv(\"../data/pubmedbert_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bc8f2a-25a8-4aae-8d96-113f44c7ffd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
