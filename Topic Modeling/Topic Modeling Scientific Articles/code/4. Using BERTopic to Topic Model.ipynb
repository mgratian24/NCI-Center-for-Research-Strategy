{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f08117b-f414-4011-b4e9-b09897d2ed9b",
   "metadata": {},
   "source": [
    "# Topic Modeling Scientific Text\n",
    "\n",
    "*This template and workflow were developed by Margaret Gratian. This set of notebooks can be used to find topics in scientific text.*\n",
    "____________________________________\n",
    "## 4. Use BERTopic to Topic Model Scientific Text\n",
    "\n",
    "**Notebook Goals**\n",
    "- Demonstrate how to use the previously embedded scientific text with the BERTopic Topic Modeling library to topic model the scientific text by:\n",
    "    1) Reducing the dimensionality of the text vectors with UMAP\n",
    "    2) Performing unsupervised clustering with HDBSCAN\n",
    "    3) Generating cluster names and labels with a variation of TF-IDF.\n",
    "\n",
    "**Requirements**\n",
    "- This notebook requires the BERTopic library. Learn more about it here: https://maartengr.github.io/BERTopic/index.html.\n",
    "- Please see the README for instructions and recommendations on proper installation.\n",
    "\n",
    "**Major Caveats**\n",
    "- This pipeline was developed within a Jupyter Notebook to make it user friendly and to provide documentation along the way on the different methods. Use this template as a guide or as a starting point for a script. \n",
    "- Some cells of this notebook should be updated by the user depending on the data source, embedding model, and other details. Some cells should not be modified regardless of the specific application. The cells that should not be modified begin with a comment that says \"Do not modify this code.\"\n",
    "\n",
    "**References**\n",
    "\n",
    "We make use of the BERTopic library, from the following paper:\n",
    "- Grootendorst, M., 2022. BERTopic: Neural topic modeling with a class-based TF-IDF procedure. arXiv preprint [arXiv:2203.05794](https://arxiv.org/abs/2203.05794).\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "The following assumes you used the recommended path for saving your data in Notebook 3. If you modified it, be sure to modify the input path here.\n",
    "\n",
    "- Input Filepath 1: \"../data/SPECTER_embeddings.csv\"\n",
    "     - Titles and abstracts embedded with the SPECTER model\n",
    "\n",
    "**Outputs**\n",
    "\n",
    "An Excel file is generated each time you run this notebook, with a path and filename generated based user defined settings and a timestamp. If you want to change this path, you must modify the notebook code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7433c-8eb9-4a04-a6e9-5a7aea65fa80",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "Run the following once when you first open this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8b650-dd68-4770-8209-f60e44306c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "# Text embedding library\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Topic Model libraries \n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de90503e-fd2c-45f2-a167-d3eb6a383579",
   "metadata": {},
   "source": [
    "***~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEGIN SECTION FOR USER INPUT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~***\n",
    "\n",
    "The following sections require user input: \n",
    "\n",
    "1. Read in Data\n",
    "2. Load in Text Model\n",
    "3. Define Input Text and Model Output Filename\n",
    "4. Define Clustering Parameters\n",
    "5. Improve Topic Representation\n",
    "\n",
    "Some cells should not be edited - these begin with a comment that says \"Do not modify this code.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baaae99-3482-4a52-bcb1-ac08168d6363",
   "metadata": {},
   "source": [
    "## 1. Read in Data\n",
    "\n",
    "Run the following once when you first open this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4594da-e424-4512-8f79-3e05bb9c1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to your input data\n",
    "input_path = \"../data/SPECTER_embeddings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c181991-fccf-432c-8904-f3c4a6058c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "input_df = pd.read_csv(input_path, index_col=0)\n",
    "\n",
    "print(len(input_df))\n",
    "\n",
    "input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44448e-20ba-4f69-84fd-ce11eeb86ce4",
   "metadata": {},
   "source": [
    "## 2. Load in Text Model\n",
    "\n",
    "The same text model that was used to produce the embeddings upstream of this notebook should be loaded in here. It is used after clustering to produce representative labels (keywords) for the clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094a4b6-4ed8-4fce-b77f-0dc7d414f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path = \"allenai-specter\"\n",
    "embedding_model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c717e-09ff-4824-9343-b48a98bd7b26",
   "metadata": {},
   "source": [
    "## 3. Define Input Text and Model Output Filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ca269-a79f-45ae-9ba0-baaddcf86dae",
   "metadata": {},
   "source": [
    "### 3.1. Set Input Text \n",
    "\n",
    "The input text refers to the text used to produce that embeddings that the model will use for clustering.\n",
    "\n",
    "Note that the input_text string provided below must exactly match one of the columns of the data read into the notebook. Embeddings of the input text should be available as a column that exactly matches the input_text column name with \"_embedding\" appended. \n",
    "\n",
    "When using SPECTER, the input text must be of the format title + \"[SEP]\" + abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3231ee-fa13-40ad-b98b-26a17e992a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input text that will be used to cluster \n",
    "# Note this must exactly match the column name associated with this data \n",
    "# This should refer to the text itself, not the embeddings of the text\n",
    "input_text = \"title_abstract\"\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e0fea-3ce6-4b83-8845-36eea22f0e48",
   "metadata": {},
   "source": [
    "### 3.2 Set Analyst Initials\n",
    "\n",
    "Set the initials of the analyst. This is used in the model result file naming.\n",
    "\n",
    "You optionally might consider adding to this a short description or reminder of the particular machine this code was run. This can be important to track for replicability because randonmess in UMAP's initialization can be impacted by the user's operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ee07a-1140-41b0-a051-95d62fa18288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set analyst initials\n",
    "# For now, there is a placeholder denoted PL\n",
    "analyst_initials = \"PL\"\n",
    "print(analyst_initials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39626d4c-6577-426f-92bc-09ff4ccac317",
   "metadata": {},
   "source": [
    "### 3.3 Set Project Name\n",
    "\n",
    "Set a short project description. This is used in model result file naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ff3af-554e-4e64-ab0e-90b8843322f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_keywords = \"tobacco_SPECTER\"\n",
    "print(project_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebf1ab4-f80d-44ff-a7e3-eb8676c4d48c",
   "metadata": {},
   "source": [
    "### 3.4 Get the Time\n",
    "\n",
    "The timestamp is used in the model output filename to uniquely identify the model run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3dc141-c289-409e-906b-8b78c30aef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT MODIFY THIS CODE ###\n",
    "timestamp =  datetime.datetime.now().strftime('%m_%d_%Y_%H%M')\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e13b6db-700c-401a-925f-8d75d00eec81",
   "metadata": {},
   "source": [
    "### 3.5 Set Output Filepath "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79aeedb-72f2-4176-b707-e38bd8f5d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder location of the model output \n",
    "# Pay careful attention to this so your file ends up where you expect \n",
    "# You may consider adding subfolders to stay organized\n",
    "output_path = \"../data/\"\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc87629-88a2-41b8-8eb7-2002ef5e7717",
   "metadata": {},
   "source": [
    "### 3.6  Output Filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad89446a-d5d1-43c6-949b-7401ba542b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the information defined above to set the name of the model output file \n",
    "output_filename = input_text + \"_\" + analyst_initials + \"_\" + timestamp + \"_\" + project_keywords + \".xlsx\"\n",
    "print(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1410388-dbd6-46e5-801f-3f8f6a960f21",
   "metadata": {},
   "source": [
    "## 4. Define Clustering Parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685cf567-4bb3-444d-8611-de58cf77d4c5",
   "metadata": {},
   "source": [
    "### 4.1 Set UMAP Parameters (Dimensionality Reduction)\n",
    "\n",
    "Adjust the UMAP parameters here.\n",
    "\n",
    "See here for more: https://umap-learn.readthedocs.io/en/latest/parameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a0915-3740-4a30-b260-8f5bcb23d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to int \n",
    "n_neighbors = 3\n",
    "\n",
    "# Set to int \n",
    "n_components = 100\n",
    "\n",
    "# Set to string, must correspond with a metric implemented in UMAP library \n",
    "umap_metric = \"cosine\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4646c8-913b-4663-bfb6-52b1cf2c59b4",
   "metadata": {},
   "source": [
    "### 4.2 Set HDBSCAN Parameters \n",
    "\n",
    "Adjust the HDBSCAN Parameters here. \n",
    "\n",
    "See here for more: https://hdbscan.readthedocs.io/en/latest/parameter_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2827ef-da28-44ff-83d8-dc9c301394cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to int \n",
    "min_cluster_size = 30 \n",
    "\n",
    "# Set to int \n",
    "min_samples = 10\n",
    "\n",
    "# Set to string, must correspond with a metric implemented in HDBSCAN library \n",
    "# Note that the choice of metric should be influenced by the choice of n_components in the umap model\n",
    "# Lower values mean you are at a lower dimensionality and metrics like euclidean should work well, \n",
    "# otherwise may need to consider a metric that works for higher dimensions\n",
    "hdbscan_metric = \"euclidean\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebfa4c-9c71-42c4-ad1b-7cb3fdc04dcb",
   "metadata": {},
   "source": [
    "## 5. Improve Topic Representation\n",
    "\n",
    "This step is used to help refine the cluster names and labels. Importantly, this does not influence clustering. Rather, this process is applied after clustering to provide a machine-generated representation of the clusters. Consider having subject matter experts review these representations as part of your model validation process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e7d5b-3a99-4d12-a998-698de867e4f0",
   "metadata": {},
   "source": [
    "### 5.1 Define Stop Words \n",
    "\n",
    "Stop words are words that should be ignored in the cluster name and label generation process. This is our opportunity to make sure words like \"the\" or \"and\" do not show up as cluster names or labels. \n",
    "\n",
    "We define a list of our own stop words to include and add this to the default list of English stop words from scikit-learn. If you want to add additional stop words, add them to the additional_words list. The default scikit-learn list will have common words like \"the\", \"and\", \"or.\" When adding words, consider ones that may be specific to your application. For example, we might add \"tobacco\" and \"cessation\" as two of our stopwords, as all of the publications in our example dataset should have these words (because this is how we searched for these publications in PubMed!). We also add a few words that we expect will be common to scientific publications (\"hypothesis\").\n",
    "\n",
    "We also add \"SEP\", the separater required for SPECTER, as a stop word. \n",
    "\n",
    "Learn more about stop words in the following:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/feature_extraction.html#using-stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52be6de-0b1c-4a24-b749-c48efecfca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional words to this list \n",
    "additional_words = [\"hypothesis\", \"hypotheses\", \"hypothesize\", \"propose\", \"proposal\", \n",
    "                    \"goal\", \"goals\", \"objective\", \"objectives\", \n",
    "                    \"aim\", \"aims\", \"abstract\", \"tobacco\", \"cessation\", \"SEP\" \n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186e5b7-f2c8-4785-90d7-723149fb0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT MODIFY THIS CODE ###\n",
    "\n",
    "# Get the default stop words from sklearn\n",
    "default_stop_words = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "# See the total number of stop words in the current list\n",
    "print(len(default_stop_words))\n",
    "\n",
    "# Add the additional stop words these to the set \n",
    "updated_stop_words = text.ENGLISH_STOP_WORDS.union(additional_words)\n",
    "\n",
    "# Convert to list \n",
    "# Add sorted() to keep alphabetical sorting\n",
    "updated_stop_words = sorted(list(updated_stop_words))\n",
    "\n",
    "# Check data type\n",
    "print(type(updated_stop_words))\n",
    "\n",
    "# Check how many stop words we have now\n",
    "print(len(updated_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92105da1-ab6f-4b31-b0ae-63a8201fcf5f",
   "metadata": {},
   "source": [
    "### 5.2 Adjust c-TF-IDF Parameters\n",
    "\n",
    "c-TF-IDF is a modification of TF-IDF developed by the BERTopic library author. It applies TF-IDF over all documents in a cluster to identify important words across the cluster, and uses these to produce a topic representation. \n",
    "\n",
    "To understand c-TF-IDF, see the following for more:\n",
    "- https://maartengr.github.io/BERTopic/getting_started/ctfidf/ctfidf.html#c-tf-idf\n",
    "- https://maartengr.github.io/BERTopic/api/ctfidf.html#bertopic.vectorizers.ClassTfidfTransformer\n",
    "\n",
    "To understand TF-IDF, see: \n",
    "- https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96622450-bc5d-4583-99e3-6f48d12011fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a tuple of ints \n",
    "# CountVectorizer range (allows you to set how many words can be put together to form a topic label)\n",
    "ngram_range = (1,3)\n",
    "\n",
    "# Set to boolean True or False\n",
    "# ctfidf parameter\n",
    "bm25_weighting = False\n",
    "\n",
    "# Set to boolean True or False\n",
    "# ctfidf parameter\n",
    "\n",
    "# Set to boolean True or False\n",
    "reduce_frequent_words = True\n",
    "\n",
    "# Set to int \n",
    "# Number of top words, based on c-TF-IDF, to consider for topic representation\n",
    "top_n_words = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8337e45-ff9c-4ec8-9d30-fe68162bac9c",
   "metadata": {},
   "source": [
    "### 5.3 Adjust MMR Parameters\n",
    "\n",
    "Use this to limit duplicative words by increasing diversity. MMR takes a float value between 0 and 1, with lower values being less diverse and values closer to 1 being as diverse as possible. Note this is still subjective and based on the embedding model!\n",
    "\n",
    "See here for more: \n",
    "- https://maartengr.github.io/BERTopic/getting_started/tips_and_tricks/tips_and_tricks.html#diversify-topic-representation\n",
    "\n",
    "Because we are adjusting values for MMR, we also need to pass in a value for the top_n_words parameters. This is set to 10 as the default and MMR returns 10 words, so diversifying the selection of 10 words for a choice of 10 words will make no difference! The library author recommends a value between 10 and 20 for top_n_words. Note that while relevant to this section, top_n_words is set as a parameter to BERTopic() not to MMR. \n",
    "\n",
    "See the following for more: \n",
    "- https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html#top_n_words\n",
    "- https://github.com/MaartenGr/BERTopic/issues/1654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c34e44-ddea-4c4b-8090-b1b85d329293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to float between 0 and 1 (non inclusive of one)\n",
    "# MMR parameter\n",
    "# Note that for this to adjust anything, the number of top_n_words to select from must be more than 10\n",
    "diversity = 0.9 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307443aa-92e3-4f6e-b8a0-12ec0ea4f7ad",
   "metadata": {},
   "source": [
    "***~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ END SECTION FOR USER INPUT ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b9a7b-1ff5-4314-9677-3d34326c113c",
   "metadata": {},
   "source": [
    "## 6. Set Up Dictionary of Definitions, Inputs, and Hyperparameters\n",
    "\n",
    "The following dictionary contains all the inputs and hyperparameters adjusted above. The values of the dictionary are based on the values set above. You should not modify this section of the code. \n",
    "\n",
    "The values of the dictionary are used in the subsequent sections of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12933c9c-1dc2-4e49-9958-87fbb687ed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT MODIFY THIS CODE ###\n",
    "\n",
    "hyperparameter_dictionary = {\n",
    "    \"data\":input_text,\n",
    "    \"embedding_model\": model_path,\n",
    "    \"n_neighbors\":n_neighbors, # UMAP \n",
    "    \"n_components\":n_components, # UMAP\n",
    "    \"umap_metric\":umap_metric, # UMAP\n",
    "    \"random_state\":42, # UMAP (set to prevent stochastic behavior between model runs)\n",
    "    \"min_cluster_size\":min_cluster_size, # HDBSCAN\n",
    "    \"min_samples\":min_samples, # HDBSCAN\n",
    "    \"hdbscan_metric\":hdbscan_metric, # HDBSCAN\n",
    "    \"stop_words\": updated_stop_words, # list of words to use as stop words in topic representation\n",
    "    \"ngram_range\":ngram_range, # CountVectorizer range (allows you to set how many words can be put together to form a topic)\n",
    "    \"bm25_weighting\":bm25_weighting, # ctfidf parameter\n",
    "    \"reduce_frequent_words\":reduce_frequent_words, #ctfidf parameter\n",
    "    \"top_n_words\":top_n_words, # Number of words to consider for topic representation\n",
    "    \"diversity\":diversity, # MMR parameter \n",
    "    \"output_filename\": output_path + output_filename\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdddf594-7041-422f-9dca-a2b6870f494a",
   "metadata": {},
   "source": [
    "## 7. Prepare Input Text and Input Text Embeddings\n",
    "\n",
    "Now, get the input text ready for topic modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1938b-c654-40c2-85ea-7b48aa319a0e",
   "metadata": {},
   "source": [
    "### 7.1 Get Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf663a75-503a-4431-a1ae-0cd6022afc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Make a copy of the input_df\n",
    "input_df_nas_dropped = input_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4d4b8-817b-4c70-ae29-4d1b2e85a35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "# If following the steps in the previous notebooks 1-3, there should be no empty values by this point. However, this is here as an additional check on the data.\n",
    "\n",
    "# Drop any Nan values\n",
    "input_df_nas_dropped = input_df_nas_dropped.dropna(subset=[input_text])\n",
    "\n",
    "# See updated shape\n",
    "print(input_df_nas_dropped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adecd082-0a3c-4677-a395-c6042d3542a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Get all the text as a list of strings\n",
    "docs = list(input_df_nas_dropped[input_text])\n",
    "print(len(docs))\n",
    "\n",
    "# Preview\n",
    "docs[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25da673a-f900-4816-a1c5-e0c32657a58d",
   "metadata": {},
   "source": [
    "### 7.2 Prepare Embeddings \n",
    "\n",
    "Embeddings are passed to the BERTopic model as a 2D NumPy array. Here, we format the column in the Pandas DataFrame which was read in by Pandas as a String."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6fe8d-bc28-4d22-9bef-61f876d5dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df_nas_dropped[[input_text + \"_embedding\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139a41c5-8f12-4d2d-9f85-f2061752f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip the leading and tailing [] and split into a list\n",
    "input_df_nas_dropped[input_text + \"_embedding\"] = input_df_nas_dropped[input_text + \"_embedding\"].str.strip('[]').str.split()\n",
    "\n",
    "input_df_nas_dropped[[input_text + \"_embedding\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4cbb6-4a8b-4f9d-b762-251f37d3e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each element of the list (currently strings) to floats\n",
    "input_df_nas_dropped[input_text + \"_embedding\"] = input_df_nas_dropped[input_text + \"_embedding\"].apply(lambda x: [float(element) for element in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743fc29-b199-4e05-874b-c8800609b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Get column of embeddings as list \n",
    "embedding_column = list(input_df_nas_dropped[input_text + \"_embedding\"])\n",
    "print(len(embedding_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf591e-fea8-4d5a-9e0f-d76521acef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Now, convert inner list AND outer list to np ndarray\n",
    "embeddings = np.array([np.array(inner_list, dtype=np.float32) for inner_list in embedding_column], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421ad9da-59c2-47d9-925d-7237bd8f9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# See the embedding 2D np array\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84cce4-d6a9-483d-9496-d4f3048256f6",
   "metadata": {},
   "source": [
    "## 8. Build BERTopic Model\n",
    "\n",
    "Use the settings defined in the Model Parameter Adjustment section to build and fit the BERTopic model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3775a-4719-4282-8ac2-4ffe9bd9df5a",
   "metadata": {},
   "source": [
    "### 8.1 Set Model Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad52d2be-0842-4b01-8026-a637bf4cf325",
   "metadata": {},
   "source": [
    "**8.1.1 UMAP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6dcd0-4ee9-459c-b121-d9202ec8fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Set the random state so we prevent stochastic results \n",
    "# Also set other key parameters - n_neighbors, n_components, and metric\n",
    "umap_model = UMAP(n_neighbors=hyperparameter_dictionary[\"n_neighbors\"], \n",
    "                  n_components=hyperparameter_dictionary[\"n_components\"], \n",
    "                  metric=hyperparameter_dictionary[\"umap_metric\"], \n",
    "                  random_state=hyperparameter_dictionary[\"random_state\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ee366-5047-407f-a0d6-3e37ff3c3e54",
   "metadata": {},
   "source": [
    "**8.1.2 HDBSCAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54e3fa-239b-4916-9730-9cbca529e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Set key parameters - min_cluster_size, min_samples, and metric\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=hyperparameter_dictionary[\"min_cluster_size\"], \n",
    "                        min_samples=hyperparameter_dictionary[\"min_samples\"], \n",
    "                        metric=hyperparameter_dictionary[\"hdbscan_metric\"],\n",
    "                        gen_min_span_tree=True # Adjust this param so we can look at relative validity \n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b87158-8905-4cd0-843e-d48e668e8f4b",
   "metadata": {},
   "source": [
    "**8.1.3 Improving the Default Topic Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912075b-60f0-4f5a-89fe-3c4e277629b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Add the modified list of stop words and the ngram range from the dictionary \n",
    "vectorizer_model = CountVectorizer(stop_words=hyperparameter_dictionary[\"stop_words\"], \n",
    "                                   ngram_range=hyperparameter_dictionary[\"ngram_range\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a87a1c-cb46-46e1-b269-4e32ffb15d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Adjust the c-TF-IDF model\n",
    "ctfidf_model = ClassTfidfTransformer(bm25_weighting=hyperparameter_dictionary[\"bm25_weighting\"], \n",
    "                                     reduce_frequent_words=hyperparameter_dictionary[\"reduce_frequent_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580f4eb9-3d01-48f7-8516-aaaa7d260d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Add additional topic representations \n",
    "\n",
    "# Set mmr_model\n",
    "mmr_model = MaximalMarginalRelevance(diversity=hyperparameter_dictionary[\"diversity\"])\n",
    "\n",
    "# KeyBERT\n",
    "# Here we do not adjust anything, but see here for more: https://maartengr.github.io/KeyBERT/index.html\n",
    "keybert_model = KeyBERTInspired()\n",
    "\n",
    "# Add these to a dictionary \n",
    "representation_model = {\n",
    "    \"KeyBERT\": keybert_model,\n",
    "    \"MMR\": mmr_model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff79760-ea37-4d96-b265-b07bdd077f01",
   "metadata": {},
   "source": [
    "### 8.2 Fit Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ea134-1629-4ed5-a8d8-60644e685920",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Set up the topic model, using the information defined above\n",
    "# Note the embedding model MUST match that defined at the top \n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    top_n_words=hyperparameter_dictionary[\"top_n_words\"],\n",
    "    representation_model=representation_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2b4c7f-aa81-4c54-bb3d-99cd8fbc2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Pass the docs and embeddings to topic model \n",
    "topics, probs = topic_model.fit_transform(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6484f-d4dd-48fc-86a2-88c50b34dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# The parameters here should match what was set in the dictionary \n",
    "# Note we don't adjust all of these methods\n",
    "topic_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5198859-0fae-49b7-904e-f04ca20087b7",
   "metadata": {},
   "source": [
    "## 9. Dataset Development\n",
    "\n",
    "Build DataFrames from the model results. These will be saved in an Excel file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3dc665-2a35-4a58-b08d-6056d16e20a4",
   "metadata": {},
   "source": [
    "### 9.1 Build Topic Level DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98067feb-7be7-483b-a02a-70e188eaf07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Do not modify the topics DataFrame itself, as this is saved as model output \n",
    "\n",
    "# Show topics\n",
    "topics_df = topic_model.get_topic_info()\n",
    "print(topics_df.shape)\n",
    "\n",
    "# Preview\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d3fc43-fff1-4e0f-a712-18eb36fa9ce5",
   "metadata": {},
   "source": [
    "### 9.2 Build Document Level DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10652dc7-b279-405e-a050-a47606954ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Do not modify the document_info DataFrame itself, as this is saved as model output \n",
    "\n",
    "document_info = topic_model.get_document_info(docs)\n",
    "print(document_info.shape)\n",
    "\n",
    "# Preview\n",
    "document_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8c5de-001d-4113-b77b-80f6f793e1fa",
   "metadata": {},
   "source": [
    "### 9.3 Build Topic Word Representation DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab059be-0172-4b0b-b7ff-2f0ced792bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Do not modify the topics_dictionary DataFrame itself, as this is saved as model output \n",
    "topics_dictionary = topic_model.get_topics()\n",
    "\n",
    "# Convert to DataFrame\n",
    "# Note that the number of columns = top_n_words\n",
    "topic_words = pd.DataFrame.from_dict(topics_dictionary, orient=\"index\")\n",
    "\n",
    "print(topic_words.shape)\n",
    "\n",
    "# Preview\n",
    "topic_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94011e60-3361-4262-80b9-35c6df9a6cf7",
   "metadata": {},
   "source": [
    "### 9.4 Get Cluster Metrics\n",
    "\n",
    "Get the following metrics and add to the dictionary: \n",
    "- Number of clusters\n",
    "- Number of documents considered noise\n",
    "- The relative validity (DBCV) score.\n",
    "    - Use this metric with caution. It is intended to help with hyperparameter selection, but unsupervised learning methods like clustering are challenging to evaluate with reliable metrics because there is no ground truth. See the following for more about the DBCV score: \n",
    "        - https://epubs.siam.org/doi/pdf/10.1137/1.9781611973440.96\n",
    "        - https://github.com/christopherjenness/DBCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a4e9a9-d772-4726-8f21-1ddbc968d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Get number of clusters\n",
    "num_clusters = topics_df.shape[0]\n",
    "print(num_clusters)\n",
    "\n",
    "# Add to dictionary\n",
    "hyperparameter_dictionary[\"num_clusters\"] = num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c52a86-3639-4df7-a247-64907e0341a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Get number of unclustered\n",
    "num_unclustered = document_info[document_info[\"Topic\"] == -1].shape[0]\n",
    "print(num_unclustered)\n",
    "\n",
    "# Add to dictionary\n",
    "hyperparameter_dictionary[\"num_documents_clustered_as_noise\"] = num_unclustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207351b7-6cac-4a06-ae0d-cb0b8abd4466",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Relative Validity - used to evaluate differences in hyperparameter choice (higher scores are better)\n",
    "# https://hdbscan.readthedocs.io/en/latest/api.html#id92\n",
    "relative_validity = topic_model.hdbscan_model.relative_validity_\n",
    "print(relative_validity)\n",
    "\n",
    "# Save this to the hyperparameter dictionary \n",
    "hyperparameter_dictionary[\"relative_validity\"] = relative_validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329c81e4-d013-4bde-901d-b0522b49091f",
   "metadata": {},
   "source": [
    "### 9.5 Build DataFrame of Model Inputs and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca157c5-611e-48ef-9764-7e182aa7986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# Build DataFrame from the dictionary\n",
    "hyperparameters_df = pd.DataFrame.from_dict(hyperparameter_dictionary, orient=\"index\", columns=[\"model_info\"])\n",
    "\n",
    "# Preview\n",
    "hyperparameters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a2673-65e3-4c91-8bdf-3a5db489d82a",
   "metadata": {},
   "source": [
    "## 10. Analyze and Extract Insights from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba96842-10c6-428d-a047-40d2e2ec968a",
   "metadata": {},
   "source": [
    "### 10.1 Visualize Data\n",
    "\n",
    "The BERTopic library provides several different ways to visualize the data. We demonstrate a few that can be useful to understand the results here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b4e33d-287a-4a11-b376-b3b186e9caf3",
   "metadata": {},
   "source": [
    "**10.1.1 Hierarchical View**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340825d-ebba-4f0c-83dc-338dff8c5242",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do not modify this code ###\n",
    "\n",
    "# See the hiearchical view of the data\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d7325-1fab-4a46-92b4-ccad607f6429",
   "metadata": {},
   "source": [
    "**10.1.2 Barchart View**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81db314a-733d-4589-a2b3-0bb2e1a1e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the parameters here to see different numbers of clusters and words \n",
    "# Note this only shows the largest clusters \n",
    "topic_model.visualize_barchart(top_n_topics=10, n_words=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252975e8-88ab-47c6-9456-5566ad6f1b21",
   "metadata": {},
   "source": [
    "**10.1.3 2-Dimensional View of Documents**\n",
    "\n",
    "Note the plot below is interactive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e0adc-5665-4f3f-a29a-677096b8d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality to view in 2 dimensions\n",
    "reduced_embeddings = UMAP(n_components=2, random_state=42).fit_transform(embeddings)\n",
    "\n",
    "# Now visualize individual documents\n",
    "topic_model.visualize_documents(docs, reduced_embeddings=reduced_embeddings, custom_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70683d8a-793b-4ade-80cc-ad6d3c391937",
   "metadata": {},
   "source": [
    "## 11. Save Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59f939-60a5-41f2-b40c-b89722299c6f",
   "metadata": {},
   "source": [
    "### 11a. Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d953bf2-a317-4a8d-8738-07613b1ea0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following outputs will be saved to: \n",
    "save_to = hyperparameter_dictionary[\"output_filename\"]\n",
    "print(save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178738d-44ee-4679-87e3-d1bc3b916792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Excel file\n",
    "with pd.ExcelWriter(save_to) as writer:  \n",
    "    hyperparameters_df.to_excel(writer, sheet_name='model_info')\n",
    "    topics_df.to_excel(writer, sheet_name='topic_overview'),\n",
    "    topic_words.to_excel(writer, sheet_name='topic_words'),\n",
    "    document_info.to_excel(writer, sheet_name='document_topic_assignment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e0651-6bef-4482-b862-cff503e5b6cd",
   "metadata": {},
   "source": [
    "### 11b. (Optional) Save Model \n",
    "\n",
    "If you want to save the model itself and not just the results, uncomment the code below. This uses [Safe Tensors](https://github.com/huggingface/safetensors) to save the model. \n",
    "\n",
    "By default this will save into the output path specified earlier, but you may wish to create a distinct folder for all the model data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685bd4bb-20b4-41cc-9b05-a93c2ee7a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you want to save the model\n",
    "#topic_model.save(output_path, serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
